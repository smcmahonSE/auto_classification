import argparse
import json
from pathlib import Path

import pandas as pd


def parse_args():
    parser = argparse.ArgumentParser(
        description="Compare model experiment runs from metrics history JSONL."
    )
    parser.add_argument(
        "--history-path",
        default="artifacts/model/metrics_history.jsonl",
        help="JSONL generated by train_model.py --history-path",
    )
    parser.add_argument(
        "--output-csv",
        default="artifacts/model/experiment_comparison.csv",
        help="CSV comparison output path",
    )
    parser.add_argument(
        "--sort-by",
        default="macro_f1",
        choices=[
            "macro_f1",
            "weighted_f1",
            "accuracy",
            "balanced_accuracy",
            "onnx_model_mb",
            "total_artifacts_mb",
        ],
    )
    parser.add_argument(
        "--ascending",
        action="store_true",
        help="Sort ascending (default is descending).",
    )
    parser.add_argument(
        "--top-n",
        type=int,
        default=10,
        help="Number of runs to print in the terminal summary table.",
    )
    return parser.parse_args()


def load_history(path: Path) -> pd.DataFrame:
    if not path.exists():
        raise FileNotFoundError(f"History file not found: {path}")
    records = []
    with path.open("r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            records.append(json.loads(line))
    if not records:
        raise ValueError(f"No run records found in {path}")
    return pd.DataFrame(records)


def main():
    args = parse_args()
    history_path = Path(args.history_path)
    output_csv = Path(args.output_csv)
    output_csv.parent.mkdir(parents=True, exist_ok=True)

    df = load_history(history_path)
    df_sorted = df.sort_values(args.sort_by, ascending=args.ascending).reset_index(drop=True)
    df_sorted.to_csv(output_csv, index=False)
    print(f"Saved comparison CSV to {output_csv}")

    # Build a cleaner terminal table while preserving full detail in CSV.
    summary = df_sorted.copy()
    summary.insert(0, "rank", range(1, len(summary) + 1))

    if "run_timestamp_utc" in summary.columns:
        summary["run_timestamp_utc"] = summary["run_timestamp_utc"].astype(str).str.replace(
            "T", " ", regex=False
        ).str.replace("+00:00", "Z", regex=False)
    if "pca_components" in summary.columns:
        summary["pca_components"] = summary["pca_components"].apply(
            lambda x: "none" if pd.isna(x) else str(int(x))
        )

    rounded_4 = ["macro_f1", "weighted_f1", "accuracy", "balanced_accuracy"]
    rounded_2 = ["onnx_model_mb", "total_artifacts_mb", "recommended_runtime_memory_mb"]
    for c in rounded_4:
        if c in summary.columns:
            summary[c] = summary[c].astype(float).round(4)
    for c in rounded_2:
        if c in summary.columns:
            summary[c] = summary[c].astype(float).round(2)

    display_cols = [
        "rank",
        "experiment_name",
        "macro_f1",
        "balanced_accuracy",
        "accuracy",
        "weighted_f1",
        "pca_components",
        "onnx_model_mb",
        "total_artifacts_mb",
        "recommended_runtime_memory_mb",
        "run_timestamp_utc",
    ]
    existing_cols = [c for c in display_cols if c in summary.columns]
    pretty = summary[existing_cols].head(max(args.top_n, 1)).rename(
        columns={
            "experiment_name": "experiment",
            "balanced_accuracy": "bal_acc",
            "weighted_f1": "w_f1",
            "pca_components": "pca",
            "onnx_model_mb": "onnx_mb",
            "total_artifacts_mb": "total_mb",
            "recommended_runtime_memory_mb": "reco_mem_mb",
            "run_timestamp_utc": "run_time_utc",
        }
    )

    print(f"\nTop {len(pretty)} runs (sorted by {args.sort_by}, ascending={args.ascending}):")
    print(pretty.to_string(index=False))


if __name__ == "__main__":
    main()
